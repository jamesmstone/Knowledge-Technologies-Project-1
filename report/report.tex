\documentclass[a4paper]{article}
%\usepackage[margin=0.75in]{geometry} % margins
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{float} % Image float [H] option
\usepackage{subfig} % Figures in figures ( I think)

\usepackage{hyperref} % \url

% Default Font
\usepackage[default]{lato}
\usepackage[T1]{fontenc}
\renewcommand{\mddefault}{l}% switch default weight to light

% Paragraphs
\setlength{\parskip}{\baselineskip}	% add space between paragraphs
\setlength{\parindent}{0pt}			% No paragraph indent

% Declare first level dot point as a -
\def\labelitemi{--}

% Smart quotes
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\title{Knowledge Technologies - Project 1: Misspelled Location Names}

\author{James Stone - 761353}

\date{August 2016}

\begin{document}
\maketitle

\section{Description}
%1. A basic description of the problem and the data set;
The task was to filter a list of tweets to ones including a location.

The data was sourced from two files, One containing locations in the US and one containing tweets.
Unfortunately, both file needed some pre-processing to make them usable. (see Method Overview)
\section{Method Overview}
%%2. An overview of your approximate matching methods. You can assume that the reader is familiar with the methods discussed in this subject, and instead focus on how they are applied to this task,

I choose to treat the sample as a monolithinc entity and use Neighbourhood Search.
I choose to write a Bash script:  `neighbourhoodSearch.sh`
Before the neighbourhood search is run I had to pre-process the data.

to do this I did the following:
\subsection{Locations file:}
\begin{description}
\item[Removed words that contain numbers] A measure to prevent lots of false positives (tweets containing numbers not involving a location), however it increases the number of false negatives (tweets about locations that have a number in their name).
\item[Removed punctuation] As a measure to help limit the number of duplicate searches, place name with punctuation will still get picked up due to th
\item[Replaced "-" and "/" with " "]
\item[Removed common small words:'of','and','a','an' 'the']
\item[Replaced spaces with newlines]
\item[Change case] in preparation for removing duplicates, I converted all the text to it's lowercase version.
\item[Removed lines that contain numbers written as words e.g. "hundred" and "thousand" (reason: same as for removing line]
\item[Remove duplicates] No uses processing the same result multiple times.
\item[Trim location length to 20 characters] As the tool I'm using to perform the neighbourhood search, "agrep", only allows search patterns of a maximum length. Additionally places that are greater than 20 characters are more likely not present in an 140 character tweet. Further, the longer the search string the longer it take to perform the search.
\end{description}

\subsection{Tweets file}
remove timestamp, id and ... so just leaving the raw tweets.



% including some indication of how you dealt with location names of more than one word (if necessary);
Unffortunately the location dataset was all over the place. It contained many duplicates (relatively and time efficient to filter out), it also contain a collection of non places, such as a series of numbers written out as words  eg "nethousdandtwohundred". It also contained a small collection of urls.
Another difficulty, was places that were more than one word long: eg "New York" these posed a problem as other places were unnesasacirly longer than one word. Even amongst Zion churches there was no consistency:

Zion Congregational Church of God in Christ
Zion Dominion Church of God
Zion Hill Baptist Church of East Detroit
Zion Hill Church of God in Christ
Zion Light Church of Christ
Zion Lutheran Church of Augsburg


For example a Cemetery in Zion: "Zion United Church of Christ Cemetery". Due to the size restrictions of agrep and time constrains of searching, it wasn't feasible to search for approximate matches of the whole string "Zion United Church of Christ Cemetery"  particularly the as the longer the string the less likely we are to match the entire phrase, even with an approximate search. Additionally you could miss cases where it has been written in an active voice over a passive voice of vice versa. For example the previous location could have easily been written as the "Christ Church Cemetery of the Zion United Church" As such I decided to split the words on spaces. However that brings its own issues. Now the data set was matching on all places that contain "of" from "Church of" or "New" from "New York".


The dataset also contained many locations joined together via hyphens, some of these were joined for genuine reasons such as ""
others however were joined as together they


punctuation

\section{Effectiveness}
%3. A discussion of the effectiveness of the approximate matching method(s) you chose,
% including a formal evaluation, and some examples to illustrate where the method(s) was/were effective/ineffective;

%James: Talk about precision

\section{Conclusion}
%4. Some conclusions about the problem of searching for misspelled location names within a collection of tweets

\end{document}
